{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QEvNm9a6kU-0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader  # Import for dataloader, load data into system\n",
        "from torchvision import datasets, transforms  #MNist Dataset\n",
        "import time    # length of duration of our training,testing, etc.\n",
        "import sys     # acts as system library and it is mandatory for any python code\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Hyperparameters for defining this simple FCNN Model ----\n",
        "Batch_size = 64    # we can take any batch size based on the capability of our RAM and particularly GPU RAM.\n",
        "Learning_rate = 0.001\n",
        "Num_epochs = 5     # mnist DATASET IS VERY EASY FOR THIS NEURAL NETWORK THATS WHY I USE 5 EPOCHS, that is sufficient."
      ],
      "metadata": {
        "id": "HVIrKCSGlRfL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- DEVICE Definition ---\n",
        "# This line automatically checks if a CUDA - enabled GPU is available.\n",
        "# if it is, the DEVICE is set to ' cuda', enabling fast GPU acceleration.\n",
        "# otherwise, it defaults to ' cpu', which uses the system's processor.\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"usung device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO_LCzyDpmji",
        "outputId": "ebfc99bd-303d-4011-b7e6-ea9b91d9027a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usung device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing\n",
        "\n",
        "\n",
        "The MNIST dataset consists 60,000 training and 10,000 testing samples of 28 x 28 grayscale(single channel) images of digits (0-9). We need to transform the data to PyTorch tensors and normalize the pixel values to the range [0,1].\n",
        "- Whenever we work with any kind of data in neural network or any machine learning models, we require to transform the raw data.\n",
        "- Very basic pre-processing are required, like normalization that should be done to any data we are feeding to our model.\n",
        "-"
      ],
      "metadata": {
        "id": "A2c_4iSdrDWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),   # Converts image to tensor \"human see as (H, W, C) -> torch see as (C, H, W)\"\",\n",
        "                             # because channel gets the priority, channel wise operations done by torch.\n",
        "    transforms.Normalize((0.1307,), (0.3081,))   # 1st one is Mean and other is standard deviationof the Gaussian function for Standard normalization for MNIST\n",
        "])\n",
        "\n",
        "# 2. Download and Load Datasets\n",
        "# NOTE: If running for the first time, PyTorch will download the dataset.\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBvQz_z0q-aw",
        "outputId": "75a4296a-630f-48a9-9dfa-31dd69f7a5ff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 57.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.67MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.8MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create Dataloaders\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=Batch_size, shuffle=True)     # here shuffle=true because we do shuffling in training to feed random data\n",
        "test_loader = DataLoader(test_dataset, batch_size = Batch_size, shuffle = False)  # here shuffle=False, we don't need shuffle here\n",
        "\n",
        "print(f\"training_samples: {len(train_dataset)}\")\n",
        "print(f\"testing_samples: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "n-oU5pGzzdmt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e6fce6c-40e0-4c4d-82ef-1dce2ca36b11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training_samples: 60000\n",
            "testing_samples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure\n",
        "plt.figure(figsize=(8, 8 ))\n",
        "\n",
        "for i in range(6) :              # Plot 6 images from 60,000\n",
        "  # 1. Get a random image and its label\n",
        "  sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
        "  img, label = train_dataset[sample_idx]\n",
        "\n",
        "\n",
        "  # 2. Reshape/Squeeze the image\n",
        "  # MNIST is automatically gave you (1, 28, 28) matrix, but matplotlib only takes 2 Dimensional thats why\n",
        "  # this squeeze function automatically finds where the one valued dimension is there and squeeze\n",
        "  img = img.squeeze()\n",
        "\n",
        "  # 3. Plot\n",
        "  plt.subplot(3, 3, i+1)\n",
        "  plt.imshow(img, cmap='gray')\n",
        "  plt.title(f\"Label: {label}\")\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "tSKK4FN6fS2D",
        "outputId": "0aa22dbd-6650-488a-ae48-ced20d66d8ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 6 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv8AAAIQCAYAAAAW6QF1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJjVJREFUeJzt3WuUVeV9P/DfEYFBRQSUeqmiLCRIq5XlBUWMaKKgogVFJMZY+kJTLw0FvEAThdSuGhIvBDHKWmqVZVtvMNaqiakRjbEIUpVG6wWMI0gRuUTEICKZ83/xX5LoyHMGz8ycc+b5fNaaFznfffb+zTDz8HVneHahWCwWAwAAaPd2qvQAAABA21D+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+a1BDQ0MUCoW4/vrrW+ycTz31VBQKhXjqqada7JxA27EuAH/MmsD2KP9t5K677opCoRCLFy+u9Cit4vXXX48JEybE4MGDo66uLgqFQjQ0NFR6LKhq7X1d+LyTTz45CoVCXHbZZZUeBapSe18TdIXqoPzTIhYsWBAzZ86MjRs3xiGHHFLpcYAqM2/evFiwYEGlxwAqSFeoDso/LeLMM8+M999/P37961/HN7/5zUqPA1SRzZs3x6RJk+Kqq66q9ChABekK1UH5ryJbtmyJa665Jo444ojo1q1b7LrrrnH88cfH/Pnzt/uem266KXr37h1dunSJE044IV5++eUmx7z22msxevTo6NGjR9TV1cWRRx4ZDz/8cMl5Nm3aFK+99lqsXbu25LE9evSIrl27ljwO2DG1vC586oc//GE0NjbG5Zdf3uz3AF+sltcEXaE6KP9V5IMPPojbb789hg4dGtOnT49p06bFmjVrYtiwYfHSSy81OX7OnDkxc+bMuPTSS2PKlCnx8ssvx0knnRSrV6/edswrr7wSxxxzTLz66qsxefLkuOGGG2LXXXeNkSNHRn19fXKeRYsWxSGHHBKzZs1q6U8VaKZaXxeWL18eP/jBD2L69OnRpUuXHfrcgaZqfU2g8nau9AD8Qffu3aOhoSE6deq07bULL7ww+vfvHzfffHPccccdnzl+2bJlsXTp0thvv/0iImL48OExaNCgmD59etx4440RETF+/Pg44IAD4vnnn4/OnTtHRMQll1wSQ4YMiauuuipGjRrVRp8d8GXU+rowadKkGDhwYIwdO7bFzgk5q/U1gcpz57+KdOjQYdsPc2NjY6xfvz62bt0aRx55ZLzwwgtNjh85cuS2H+aIiKOPPjoGDRoUjz32WERErF+/Pp588skYM2ZMbNy4MdauXRtr166NdevWxbBhw2Lp0qWxcuXK7c4zdOjQKBaLMW3atJb9RIFmq+V1Yf78+TF37tyYMWPGjn3SwHbV8ppAdVD+q8zdd98dhx12WNTV1UXPnj1jr732ikcffTQ2bNjQ5NiDDz64yWv9+vXbtm3WsmXLolgsxtVXXx177bXXZz6mTp0aERHvvfdeq34+QPlqcV3YunVrfOc734lvfetbcdRRR5V9PuAPanFNoHr4tZ8qcs8998S4ceNi5MiRccUVV0SvXr2iQ4cOcd1118Wbb765w+drbGyMiIjLL788hg0b9oXH9O3bt6yZgdZVq+vCnDlz4vXXX4/Zs2c32cd748aN0dDQEL169Ypddtml7GtBTmp1TaB6KP9V5MEHH4w+ffrEvHnzolAobHv90//y/rylS5c2ee2NN96IAw88MCIi+vTpExERHTt2jK9//estPzDQ6mp1XVi+fHl88skncdxxxzXJ5syZE3PmzIn6+voYOXJkq80A7VGtrglUD7/2U0U6dOgQERHFYnHbawsXLtzug3Eeeuihz/we3qJFi2LhwoVx6qmnRkREr169YujQoTF79uxYtWpVk/evWbMmOc+X2dIPaFm1ui6MHTs26uvrm3xERJx22mlRX18fgwYNSp4DaKpW1wSqhzv/bezOO++Mn/3sZ01eHz9+fIwYMSLmzZsXo0aNitNPPz3eeuutuO2222LAgAHx4YcfNnlP3759Y8iQIXHxxRfHxx9/HDNmzIiePXvGlVdeue2YW265JYYMGRKHHnpoXHjhhdGnT59YvXp1LFiwIN55551YsmTJdmddtGhRnHjiiTF16tSS/5Bnw4YNcfPNN0dExLPPPhsREbNmzYo99tgj9thjj7jsssua8+WBLLXHdaF///7Rv3//L8wOOuggd/whoT2uCRG6QtUo0ib++Z//uRgR2/1YsWJFsbGxsfhP//RPxd69exc7d+5cHDhwYPGRRx4p/tVf/VWxd+/e28711ltvFSOi+KMf/ah4ww03FPfff/9i586di8cff3xxyZIlTa795ptvFi+44ILi3nvvXezYsWNxv/32K44YMaL44IMPbjtm/vz5xYgozp8/v8lrU6dOLfn5fTrTF3388ezAH7T3deGLRETx0ksv/VLvhfauva8JukJ1KBSLf/T/GwEAAO2W3/kHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE81+wm+hUGjNOYASqvGRHNYFqKxqWxesCVBZzVkT3PkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmdi50gMAVKvzzz8/md99993J/KSTTkrmTz/99A7PBNBapkyZUvKY//zP/0zmixcvbqlxaCXu/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ+/xTNcaMGZPM77333mQ+fPjwZP7zn/98h2eifevZs2cy//a3v53Mi8ViMj/jjDOSeQ77/O+7777JfMGCBcn8l7/8ZTK/6KKLkvlHH32UzIE/uOCCC0oec/LJJyfzUs83ofLc+QcAgEwo/wAAkAnlHwAAMqH8AwBAJpR/AADIhPIPAACZUP4BACAT9vmnzRxzzDHJfOrUqcm81J7qpfYWts8/n7fPPvsk886dO5d1/lJ73Hfq1CmZb9mypazrV4NRo0Yl8/322y+Zn3feecn8gQceSObz589P5hs3bkzmAO2NO/8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkolAstXn6pwcWCq09CzXulFNOSeZ33HFHMi+1J/r//M//JPPjjjsumW/atCmZV7tm/qi2qfa+Lnz3u99N5t///veTeamvzwEHHJDMV65cmcxrwS677JLM/+3f/i2ZjxgxIpmX+rkotS4sXLgwmVe7alsX2vua0N69+uqrJY9ZtWpVMi/1zB1aV3PWBHf+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyMTOlR6A2jFgwIBk/sgjjyTzDh06JPM1a9Yk83HjxiXzWt/Hn7Z34IEHJvPzzz+/bQZpx0r9XC5durSNJgFawuOPP17pESiTO/8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkwj7/bLPPPvsk83nz5iXzUvv4lzJlypRkvmTJkrLOD5+39957J/N+/fqVdf6ddnJ/pZRCoZDMS30NGxsbyzo/sGM8U6f2+ZsJAAAyofwDAEAmlH8AAMiE8g8AAJlQ/gEAIBPKPwAAZEL5BwCATNjnPxN/+qd/WvKYRx99NJl/5StfSeal9ts+//zzk/n999+fzKGtFYvFst4/e/bsZP7uu++Wdf72oNTXuNS6Uur95f4ZQnvSv3//ZF7us02oDe78AwBAJpR/AADIhPIPAACZUP4BACATyj8AAGRC+QcAgEwo/wAAkAn7/Gfi1ltvLXnMn//5nyfzUvtt/+hHP0rmDzzwQDL//e9/n8xhR/Xs2TOZ//3f/32rXv9///d/k3kO3/OdO3dO5vvss08bTQKUUigUKj0CbcCdfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADJhn/924i/+4i+S+eGHH172Nf77v/87mU+ePLnsa0BLOuuss5L5aaed1qrXnzlzZquevxb06tUrmZ977rkVvf4uu+ySzDdt2tSS40DNW7ZsWaVHoEzu/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ+/zXiC5duiTzRx55JJnvu+++Ja/x1ltvJfOzzz675Dmgmnzve99r1fP/+7//e6uevxYceOCByXzKlCltM8h21NfXJ/NHH300md94443J/Omnn97hmaCW/frXv670CJTJnX8AAMiE8g8AAJlQ/gEAIBPKPwAAZEL5BwCATCj/AACQCeUfAAAyYZ//GnHEEUck8+bs41/Ktddem8xXrFhR9jWgLRUKhbLyUp555pmy3t+vX79kfvrpp5d1/lJOOOGEksecccYZrTpDKTvtlL5H1djYWNb5R4wYkcznz5+fzO3zTy3p0aNHMn/55ZdLnmP16tUtNQ4V4s4/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgEx7yVSV22223ZP7QQw8l81IPK3r22WdLzlDqGlBtSj2kavfdd0/mxWKxrOtfffXVyXzixInJvK6uLpmXeiBPuZrzkLNyv0blKvUQr1LzrVu3LpnPmzcvmd9+++3JHGrJ6NGjk/nmzZtLnuOTTz5pqXGoEHf+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyIR9/qvEGWeckcy7d++ezEvtdX3NNdeUnGHDhg0lj4Fq8vTTTyfzUt/TpZ6vUUq3bt2S+R577JHMW3sP/YaGhmS+atWqVr1+RES/fv2Sec+ePcs6/5NPPpnMJ0yYkMxfeeWVsq4P1aRLly7JfMSIEcn8/fffb8FpqFbu/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ+/xXiQEDBpT1/t/+9rfJvC3284Zqc9tttyXziy66qFWvv9NO6fsrjY2Nyfztt99O5rNmzUrmL730UjJftmxZMm8J9913XzI/++yzyzr/unXrkrl9/MnJnnvumcwPPvjgZF5qTaF9cOcfAAAyofwDAEAmlH8AAMiE8g8AAJlQ/gEAIBPKPwAAZEL5BwCATNjnv4185StfSebjxo1L5sViMZnPmTMnmb/22mvJHNqj6667rqyc6vfwww9XegSoGaW6xIMPPthGk1BJ7vwDAEAmlH8AAMiE8g8AAJlQ/gEAIBPKPwAAZEL5BwCATCj/AACQCfv8t5GpU6cm83333TeZ/+53v0vmEydO3OGZACqtUCgk8512St+j+uUvf9mS40BN69u3bzJ/++23k/nzzz/fkuNQpdz5BwCATCj/AACQCeUfAAAyofwDAEAmlH8AAMiE8g8AAJlQ/gEAIBP2+W8hdXV1yXz//fcv6/xvvPFGWe8HqEbFYjGZNzY2ttEkUPsOPfTQZP7RRx8l802bNrXkOFQpd/4BACATyj8AAGRC+QcAgEwo/wAAkAnlHwAAMqH8AwBAJpR/AADIhH3+W0i3bt2S+eDBg8s6/7XXXlvW+wEqoaGhoVXPP23atGQ+ceLEZL5x48YWnAYq6+STT670CNQAd/4BACATyj8AAGRC+QcAgEwo/wAAkAnlHwAAMqH8AwBAJpR/AADIhH3+q8SGDRuS+TPPPNNGkwC0nB//+MfJ/KKLLkrmu+++ezL/67/+62S+ZcuWZH7ppZcmc6glu+66a6VHoAa48w8AAJlQ/gEAIBPKPwAAZEL5BwCATCj/AACQCeUfAAAyofwDAEAm7PNfJX76058m8/Xr17fRJAAt5//+7/+S+R133JHMJ0yYUNb1DzvssLLeD7Vk5cqVyXzRokVtNAnVzJ1/AADIhPIPAACZUP4BACATyj8AAGRC+QcAgEwo/wAAkAnlHwAAMlEoFovFZh1YKLT2LDXtT/7kT5J5qb2uf/e73yXzgw46KJmvW7cumVP7mvmj2qasC1BZ1bYuWBOgspqzJrjzDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCbs8w81otr2846wLkClVdu6YE2AyrLPPwAAsI3yDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADJRKBaLxUoPAQAAtD53/gEAIBPKPwAAZEL5BwCATCj/AACQCeUfAAAyofwDAEAmlH8AAMiE8g8AAJlQ/gEAIBPKPwAAZEL5BwCATCj/AACQCeUfAAAyofwDAEAmlH8AAMiE8l+DGhoaolAoxPXXX99i53zqqaeiUCjEU0891WLnBNqOdQH4Y9YEtkf5byN33XVXFAqFWLx4caVHaRWvv/56TJgwIQYPHhx1dXVRKBSioaGh0mNBVWvv68LnnXzyyVEoFOKyyy6r9ChQldr7mjBt2rQoFApNPurq6io9WlZ2rvQAtA8LFiyImTNnxoABA+KQQw6Jl156qdIjAVVk3rx5sWDBgkqPAVSBW2+9NXbbbbdt/7tDhw4VnCY/yj8t4swzz4z3338/unbtGtdff73yD2yzefPmmDRpUlx11VVxzTXXVHocoMJGjx4de+65Z6XHyJZf+6kiW7ZsiWuuuSaOOOKI6NatW+y6665x/PHHx/z587f7nptuuil69+4dXbp0iRNOOCFefvnlJse89tprMXr06OjRo0fU1dXFkUceGQ8//HDJeTZt2hSvvfZarF27tuSxPXr0iK5du5Y8DtgxtbwufOqHP/xhNDY2xuWXX97s9wBfrD2sCcViMT744IMoFovNfg8tR/mvIh988EHcfvvtMXTo0Jg+fXpMmzYt1qxZE8OGDfvCO+lz5syJmTNnxqWXXhpTpkyJl19+OU466aRYvXr1tmNeeeWVOOaYY+LVV1+NyZMnxw033BC77rprjBw5Murr65PzLFq0KA455JCYNWtWS3+qQDPV+rqwfPny+MEPfhDTp0+PLl267NDnDjRV62tCRESfPn2iW7du0bVr1zj//PM/Mwutz6/9VJHu3btHQ0NDdOrUadtrF154YfTv3z9uvvnmuOOOOz5z/LJly2Lp0qWx3377RUTE8OHDY9CgQTF9+vS48cYbIyJi/PjxccABB8Tzzz8fnTt3joiISy65JIYMGRJXXXVVjBo1qo0+O+DLqPV1YdKkSTFw4MAYO3Zsi50TclbLa0L37t3jsssui2OPPTY6d+4czzzzTNxyyy2xaNGiWLx4cey+++4tch3S3PmvIh06dNj2w9zY2Bjr16+PrVu3xpFHHhkvvPBCk+NHjhy57Yc5IuLoo4+OQYMGxWOPPRYREevXr48nn3wyxowZExs3boy1a9fG2rVrY926dTFs2LBYunRprFy5crvzDB06NIrFYkybNq1lP1Gg2Wp5XZg/f37MnTs3ZsyYsWOfNLBdtbwmjB8/Pm6++eY477zz4uyzz44ZM2bE3XffHUuXLo2f/OQnO/iV4MtS/qvM3XffHYcddljU1dVFz549Y6+99opHH300NmzY0OTYgw8+uMlr/fr127bF5rJly6JYLMbVV18de+2112c+pk6dGhER7733Xqt+PkD5anFd2Lp1a3znO9+Jb33rW3HUUUeVfT7gD2pxTdie8847L/bee+944oknWu0afJZf+6ki99xzT4wbNy5GjhwZV1xxRfTq1Ss6dOgQ1113Xbz55ps7fL7GxsaIiLj88stj2LBhX3hM3759y5oZaF21ui7MmTMnXn/99Zg9e3aTZ35s3LgxGhoaolevXrHLLruUfS3ISa2uCSn7779/rF+/vlWvwR8o/1XkwQcfjD59+sS8efOiUChse/3T//L+vKVLlzZ57Y033ogDDzwwIv7/P6iJiOjYsWN8/etfb/mBgVZXq+vC8uXL45NPPonjjjuuSTZnzpyYM2dO1NfXx8iRI1ttBmiPanVN2J5isRgNDQ0xcODANr92rvzaTxX59CEXf7z11cKFC7f7YJyHHnroM7+Ht2jRoli4cGGceuqpERHRq1evGDp0aMyePTtWrVrV5P1r1qxJzvNltu8CWlatrgtjx46N+vr6Jh8REaeddlrU19fHoEGDkucAmqrVNWF757r11ltjzZo1MXz48JLvp2W489/G7rzzzvjZz37W5PXx48fHiBEjYt68eTFq1Kg4/fTT46233orbbrstBgwYEB9++GGT9/Tt2zeGDBkSF198cXz88ccxY8aM6NmzZ1x55ZXbjrnllltiyJAhceihh8aFF14Yffr0idWrV8eCBQvinXfeiSVLlmx31kWLFsWJJ54YU6dOLfkPeTZs2BA333xzREQ8++yzERExa9as2GOPPWKPPfaIyy67rDlfHshSe1wX+vfvH/379//C7KCDDnLHHxLa45oQEdG7d+8499xz49BDD426urr41a9+Fffee28cfvjh8e1vf7v5XyDKovy3sVtvvfULXx83blyMGzcu3n333Zg9e3Y8/vjjMWDAgLjnnnvigQceiKeeeqrJey644ILYaaedYsaMGfHee+/F0UcfHbNmzYp99tln2zEDBgyIxYsXx/e///246667Yt26ddGrV68YOHBgiz5p87e//W1cffXVn3nthhtuiIj//8Ou/MP2tdd1Afhy2uua8M1vfjP+67/+K+bOnRubN2+O3r17x5VXXhnf/e53/fufNlQoerwaAABkwe/8AwBAJpR/AADIhPIPAACZUP4BACATyj8AAGRC+QcAgEwo/wAAkIlmP+SrUCi05hxACdX4SA7rAlRWta0L1gSorOasCe78AwBAJpR/AADIhPIPAACZUP4BACATyj8AAGRC+QcAgEwo/wAAkAnlHwAAMqH8AwBAJpR/AADIhPIPAACZUP4BACATyj8AAGRC+QcAgEwo/wAAkAnlHwAAMqH8AwBAJpR/AADIhPIPAACZUP4BACATyj8AAGRC+QcAgEwo/wAAkAnlHwAAMqH8AwBAJpR/AADIhPIPAACZUP4BACATyj8AAGRC+QcAgEzsXOkBACqlWCwm88bGxmT+8ccfJ/Njjz02mS9ZsiSZA0BLc+cfAAAyofwDAEAmlH8AAMiE8g8AAJlQ/gEAIBPKPwAAZEL5BwCATBSKpTa6/vTAQqG1ZyFhzJgxyfy+++5L5ueee27Ja9x///07NBNtq5k/qm2q1teF3//+98m81D7/pTz66KPJfOTIkWWdH6ptXaj1NYH2r3Pnzsm8a9euyXzz5s3J/MMPP9zhmVpSc9YEd/4BACATyj8AAGRC+QcAgEwo/wAAkAnlHwAAMqH8AwBAJpR/AADIxM6VHoC2YQ9/aGrw4MHJ/KKLLkrmF1xwQTLv0KFDMu/YsWMy/+STT5J5NejUqVMyv+mmm5L5FVdckcy3bNmSzLdu3ZrMgbx87WtfS+al1vXRo0cn8+XLlyfzgw46KJlXA3f+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyIR9/mtEqX1lSxkzZkzJYzwLgNwsXLgwmY8YMaKs8w8fPjyZX3LJJcn8xz/+cVnXbwuzZ89O5ueff34yL7Xn9tixY5P53LlzkzlQXfr27ZvM//Iv/zKZT548OZl369YtmZd6/kopq1evLuv91cCdfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADJhn/8a8dxzzyXzFStWJPPRo0eXvIZ9/oHPO/LII5P5EUcc0UaTANWg1Jpw0003JfOjjjoqmXfs2DGZFwqFZF4sFpN5KT/5yU+SeS08f6UUd/4BACATyj8AAGRC+QcAgEwo/wAAkAnlHwAAMqH8AwBAJpR/AADIhH3+24lSzwEA+LwOHTqUPKbUntyHHHJIWTM88MADyfyJJ54o6/yQkwMPPDCZn3jiicl88uTJJa9x8MEH78hILa6+vj6ZX3fddcl88eLFLTlOTXLnHwAAMqH8AwBAJpR/AADIhPIPAACZUP4BACATyj8AAGRC+QcAgEzY5x8gU/vuu2/JY2bOnNmqM6xbty6Zb9iwoVWvD9Xkq1/9ajI/55xzkvnYsWOTeY8ePZJ5oVBI5hERxWKx5DEp//iP/5jM//Vf/zWZv/7662VdH3f+AQAgG8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyIR9/gHaqW984xvJfPjw4W00CeRhyJAhyfzyyy9P5ieeeGIy32233XZ4pmpz8MEHJ/M1a9a00ST5cucfAAAyofwDAEAmlH8AAMiE8g8AAJlQ/gEAIBPKPwAAZEL5BwCATNjnv51YsWJFMp84cWIbTQI01+TJk5P5iy++mMwPOOCAZD5jxoxk3q1bt2TeEhoaGpL5tdde2+ozQEvp27dvMn/iiSeSeadOnZJ5sVjc4Zn+2HvvvZfM169fn8wfe+yxktc47bTTknnXrl2T+bnnnpvMSz1/5JRTTknmixcvTua48w8AANlQ/gEAIBPKPwAAZEL5BwCATCj/AACQCeUfAAAyofwDAEAm7PPfTixcuLDsc4wZMyaZ33///WVfA2rJSy+9lMzXrFmTzPfaa69kvueeeybzX/ziF8m8FmzZsiWZl9qXHKrJhx9+mMxL/V18/PHHJ/N/+Zd/Sea33XZbMn/77beT+cqVK5N5c1xxxRXJvEePHsl82bJlybzU80cOPfTQZG6f/9Lc+QcAgEwo/wAAkAnlHwAAMqH8AwBAJpR/AADIhPIPAACZUP4BACAT9vlvJ5YvX172OQYNGpTM7fNPbubOnZvM/+7v/i6Zl9rnH6gt7777bjI/4YQT2miS6rV+/fpk/uqrrybzY489Npn369dvh2fis9z5BwCATCj/AACQCeUfAAAyofwDAEAmlH8AAMiE8g8AAJlQ/gEAIBPKPwAAZMJDvtqJ5557ruxz7L///i0wCeTjG9/4RjJ//PHHk3mph4B17949mW/cuDGZr1q1KpnvvHPpvwL69OlT8hiAT40aNSqZH3bYYcm8WCwm886dO+/wTHyWO/8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkwj7/mVixYkWlR4B255133knmf/Znf5bMzz777GQ+dOjQZP7SSy8l8zvuuCOZN+fZHr/5zW9KHgPko66uLpl/73vfS+a77LJLWdd//vnny3o/7vwDAEA2lH8AAMiE8g8AAJlQ/gEAIBPKPwAAZEL5BwCATCj/AACQCfv8Z+K5556r9AjA58ydO7esHPisc845J5m/+OKLyXzZsmUtOU7Nac4e/KWeHzJgwICyZpgwYUIyr6+vL+v8uPMPAADZUP4BACATyj8AAGRC+QcAgEwo/wAAkAnlHwAAMqH8AwBAJuzzn4kVK1aUPGbixIltMAkAtI6ZM2cm8xdeeCGZX3zxxcl8+fLlOzxTLbn77rtLHnPWWWeVdY233347md91113JfPPmzWVdH3f+AQAgG8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyIR9/jOxcOHCss9xzDHHJPPnnnuu7GsA7Uv37t2T+de+9rVk/otf/KIlx6GdKxQKyfzUU09N5g0NDcn8lltuSeb33ntvMm9t5513XjIvtUf/3nvvXfIaxWIxmb/44ovJ/Ljjjkvm9vFvfe78AwBAJpR/AADIhPIPAACZUP4BACATyj8AAGRC+QcAgEwo/wAAkIlCsdSGrZ8eWGLvXKrb/vvvX/KYZ599Npk/8MADyXzSpEk7NBM7ppk/qm3KulDbmrMu/OY3v2nVGZYvX57ML7jggmS+atWqZD5jxoxk/g//8A/JfPLkycm8U6dOybyUM888s6z3V9u6UOk1odQ+9TfeeGMyHzVqVDIv98+71Nen0n+eW7duLXnMz3/+82T+N3/zN8l85cqVOzQTO6Y530Pu/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ+/yzzf3335/MzznnnGTue6R1VXr/5y/iz7y29erVq+QxTz/9dDLv27dvS43zhT755JNkXurnotS+7Fu2bEnmL7zwQlnXL+WrX/1qWe+vtnWh1teEo48+OpmXeo7AaaedlswvuuiiZN7Q0JDMe/funcxfeeWVZP7Tn/40mf/Hf/xHMo+I+NWvflXyGCrHPv8AAMA2yj8AAGRC+QcAgEwo/wAAkAnlHwAAMqH8AwBAJpR/AADIhH3+2WbMmDHJ/L777kvmvkdaV7Xt5x3hzzwHhx9+eDIfNWpUMv/bv/3bZN61a9cdHekz3n333WR+5513lnX+a6+9Nplv3bq1rPOXq9rWBWtCWs+ePZP5xx9/nMw7d+6czDdt2pTMP/roo2RO7bPPPwAAsI3yDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADJhn3+ardS3yrnnnpvM77///pYcJzvVtp93hHWB0gYPHpzMzzrrrGQ+fvz4ZH7KKack8/nz5yfzWldt64I1ASrLPv8AAMA2yj8AAGRC+QcAgEwo/wAAkAnlHwAAMqH8AwBAJpR/AADIhH3+abbly5cn8zFjxiTz5557riXHyU617ecdYV2ASqu2dcGaAJVln38AAGAb5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkwj7/UCOqbT/vCOsCVFq1rQvWBKgs+/wDAADbKP8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE8o/AABkQvkHAIBMKP8AAJAJ5R8AADKh/AMAQCaUfwAAyITyDwAAmVD+AQAgE4VisVis9BAAAEDrc+cfAAAyofwDAEAmlH8AAMiE8g8AAJlQ/gEAIBPKPwAAZEL5BwCATCj/AACQCeUfAAAy8f8AwAqjJLKo8dkAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fully Connected Neural Network ($FCNN$)\n",
        "\n",
        "The FCNN (also known as a multilayer Perceptron or MLP) ia the most basic architecture. it is great for tabular (1D) data and we need to convert our image or 2D matrix into 1D vector.\n",
        "\n",
        "\n",
        "### Formatting Data and Labels\n",
        "\n",
        "We can flatten this array into a vector of **28 X 28 = 784** numbers. it doesn't matter how we flatten the array, as long as we're consistent between images. From this perspective, the MNIST images are just a bunch of points in a 784-dimensional vector space. The data should always be of the format (Number of data points, data point dimension). In this case the training data will be of format **60,000 X 784.**"
      ],
      "metadata": {
        "id": "dMQCI4zFi2KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a FCNN class\n",
        "class FCNN(nn.Module):       # This is the SuperClass of all Neural Network\n",
        "\n",
        "# Two functions are mandetory for each in the class, one is \"__init__ function\" and other \"forward\" function\n",
        "# __init__ is create for model architecture\n",
        "  def __init__(self, input_size=784, num_classes=10) :\n",
        "    super(FCNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, 128)  # Input layer, 128 Neurons\n",
        "    self.fc2 = nn.Linear(128, 64)          # Middle layer\n",
        "    self.fc3 = nn.Linear(64, num_classes)  # Output layer\n",
        "\n",
        "# Final output is given by forward function\n",
        "  def forward(self, x) :\n",
        "    # Flatten the input: (Batch, 1, 28, 28) -> (Batch, 784)\n",
        "    x = x.view(x.size(0), -1)   # We just minus the 1 to crush the channel dimension\n",
        "    x = F.relu(self.fc1(x))     # 784 X 128 weight matrix will be multiplied by x + 128 biases\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "# This is only for count the number of parameters we define\n",
        "def count_parameters(model) :\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Models defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeLjE7N8iyt4",
        "outputId": "21d76aaa-2ced-484a-cc43-159d764a999e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Testing Functions"
      ],
      "metadata": {
        "id": "9exXdNR2vESA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, optimizer, epoch) :\n",
        "  # Runs a single training epoch.\n",
        "  model.train()      # say model to train\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(train_loader) :\n",
        "    # Crucially, send data and target to the selected device\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)        # Compute mathemathical inside no of layers we define\n",
        "\n",
        "    # Use Cross-Entropy loss for classification\n",
        "    loss = F.cross_entropy(output, target)    # y=target, yhat=output here\n",
        "    loss.backward()              # Backpropagation\n",
        "    optimizer.step()             # Weight optimizer new Ws layer by layer\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  # this line say information how the training going on\n",
        "  avg_loss = running_loss / len(train_loader)\n",
        "  print(f\"Epoch {epoch} | Training Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "MCRVoeAlim21"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader):\n",
        "  # Evaluate the model on the test set.\n",
        "  model.eval()      # it is necessary to call, no optimization here, nothing is changed here in test\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():       # No gradients are calculated during testing\n",
        "    for data, target in test_loader:\n",
        "      # Crucially, send data and target to the selected device\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "\n",
        "      # Sum up batch loss\n",
        "      test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "\n",
        "      # Get the index of the max log-probability (the prediction), which label giving the highest probability\n",
        "      pred = output.argmax(dim=1, keepdim=True)    # Label predictor\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss/= len(test_loader.dataset)\n",
        "  accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "  print(f\"\\nTest set: Avg Loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)}\")\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "kWxr93C54iYk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execution - FCNN"
      ],
      "metadata": {
        "id": "U0zHaPWk8PiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=========================================\")\n",
        "print(\"1. Starting FCNN Training (Baseline)\")\n",
        "print(\"=========================================\")\n",
        "\n",
        "# Explicitly passing input_size=784 and num_classes=10 to match MNIST data\n",
        "fcnn_model = FCNN(input_size=784, num_classes=10).to(device)\n",
        "fcnn_optimizer = optim.Adam(fcnn_model.parameters(), lr=Learning_rate)    # Adam optimizer function use here\n",
        "\n",
        "print(f\"FCNN Parameters: {count_parameters(fcnn_model)}\")\n",
        "fcnn_start_time = time.time()\n",
        "\n",
        "# Here the training happens till the number of epochs\n",
        "for epoch in range(1, Num_epochs + 1):\n",
        "  train_model(fcnn_model, train_loader, fcnn_optimizer, epoch)\n",
        "\n",
        "fcnn_test_accuracy = test_model(fcnn_model, test_loader)\n",
        "\n",
        "fcnn_total_time = time.time() - fcnn_start_time\n",
        "print(f\"FCNN Total Training Time: {fcnn_total_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfdxmPL-8IwA",
        "outputId": "4d5e63f5-19a3-4e9f-9c5d-dba0a174957f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================\n",
            "1. Starting FCNN Training (Baseline)\n",
            "=========================================\n",
            "FCNN Parameters: 109386\n",
            "Epoch 1 | Training Loss: 0.2749\n",
            "Epoch 2 | Training Loss: 0.1127\n",
            "Epoch 3 | Training Loss: 0.0799\n",
            "Epoch 4 | Training Loss: 0.0611\n",
            "Epoch 5 | Training Loss: 0.0497\n",
            "\n",
            "Test set: Avg Loss: 0.0879, Accuracy: 9744/10000\n",
            "FCNN Total Training Time: 74.86 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving and reloading a model to test in future"
      ],
      "metadata": {
        "id": "eL6iG2-y_Qtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyWvzE0Q-a71",
        "outputId": "16b67f60-b2c8-4aa0-d4ce-35a4316abcea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fcnn_model = FCNN(input_size=784, num_classes=10).to(device)\n",
        "fcnn_optimizer = optim.Adam(fcnn_model.parameters(), lr=Learning_rate)\n",
        "\n",
        "print(f\"FCNN Parameters: {count_parameters(fcnn_model)}\")\n",
        "fcnn_start_time = time.time()\n",
        "\n",
        "# --- TRAINING LOOP ---\n",
        "for epoch in range(1, Num_epochs + 1):\n",
        "  train_model(fcnn_model, train_loader, fcnn_optimizer, epoch)\n",
        "\n",
        "fcnn_total_time = time.time() - fcnn_start_time\n",
        "print(f\"FCNN Total Training Time: {fcnn_total_time:.2f}seconds\")\n",
        "\n",
        "# --- Save TO Drive ---\n",
        "# Define the filename\n",
        "import os\n",
        "# --- Save TO Drive ---\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/models\"\n",
        "\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "model_file = os.path.join(save_path, \"fcnn_model.pth\")\n",
        "\n",
        "torch.save(fcnn_model.state_dict(), model_file)\n",
        "\n",
        "print(f\"Model saved at:\", {model_file})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzRoTEOJ_ryi",
        "outputId": "a2a17c07-8b78-4490-d87d-bcaeb2cf73fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FCNN Parameters: 109386\n",
            "Epoch 1 | Training Loss: 0.2732\n",
            "Epoch 2 | Training Loss: 0.1137\n",
            "Epoch 3 | Training Loss: 0.0793\n",
            "Epoch 4 | Training Loss: 0.0605\n",
            "Epoch 5 | Training Loss: 0.0505\n",
            "FCNN Total Training Time: 74.70seconds\n",
            "Model saved at: {'/content/drive/MyDrive/models/fcnn_model.pth'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fcnn_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w3rstktBnWu",
        "outputId": "bbfb5f87-d3b1-40e8-c34b-60b31c7d7e62"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FCNN(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sav_0VzkCikY",
        "outputId": "4eaf9a48-16d9-41e7-d277-64aa0fbbce3c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(fcnn_model.state_dict(), \"fcnn_model.pth\")"
      ],
      "metadata": {
        "id": "vkhT8KvbCnTW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anytime once the model is saved we can test it anytime as many as we want to test it. And as many as ways we can."
      ],
      "metadata": {
        "id": "KR3ZyUT6mc9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-initialize the model structure\n",
        "\n",
        "now, has happened only the architecture, the shell of the model has been created, that there will be three layers, the input layers dimension will be 784, number of classes will be 10.\n",
        "\n",
        "\n",
        "**So There comes how to test a model.**\n",
        "\n",
        "\n",
        "let's reinitialize the model"
      ],
      "metadata": {
        "id": "znptzLam760n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Re-initialize the model structure\n",
        "reloaded_model = FCNN(input_size=784, num_classes=10).to(device)\n",
        "\n",
        "# 2. Load the weights from Google Drive\n",
        "model_file = \"/content/drive/MyDrive/models/fcnn_model.pth\"\n",
        "reloaded_model.load_state_dict(torch.load(model_file))  # here reload the model, means whatever layers we have specified the structure\n",
        "# we have created in this line. in each and every neuron, now the optimized parameters or the learned parameters will be loaded through this load-staked dictionary.\n",
        "\n",
        "# Run The Test\n",
        "fcnn_test_accuracy = test_model(reloaded_model, test_loader)\n",
        "print(f\"Reloade Model Accuracy: {fcnn_test_accuracy:2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc54bXQU7DEl",
        "outputId": "9a1291bd-0307-4012-ce06-c4ccc865075e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Avg Loss: 0.0829, Accuracy: 9741/10000\n",
            "Reloade Model Accuracy: 97.410000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/mnist-classification-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h4NRXD6HYJk",
        "outputId": "2e7b5551-50bb-4c6f-c82b-74c57215aeea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mnist-classification-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lMUq5rjoEIBg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}